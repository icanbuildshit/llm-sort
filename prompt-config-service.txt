// src/services/promptEngineeringService.ts

import { z } from 'zod';

/**
 * Prompt Engineering Service
 * 
 * This service manages the configuration and generation of prompts for various AI tasks
 * across the DynaGen Lending platform. It implements best practices for enterprise AI
 * task management through advanced prompt engineering techniques.
 */

// Define the schema for prompt templates
export const PromptTemplateSchema = z.object({
  id: z.string(),
  name: z.string(),
  description: z.string().optional(),
  systemPrompt: z.string(),
  userPromptTemplate: z.string(),
  parameters: z.array(z.object({
    name: z.string(),
    description: z.string().optional(),
    required: z.boolean().default(false)
  })).optional(),
  temperature: z.number().min(0).max(1).default(0.7),
  maxTokens: z.number().optional(),
  responseFormat: z.enum(['json', 'text', 'markdown']).default('text'),
  version: z.string().default('1.0'),
  lastUpdated: z.string().optional(),
  category: z.enum([
    'call_analysis', 
    'loan_qualification', 
    'customer_engagement', 
    'agent_performance', 
    'compliance', 
    'risk_assessment'
  ]),
  tags: z.array(z.string()).optional()
});

export type PromptTemplate = z.infer<typeof PromptTemplateSchema>;

// Define schema for prompt parameters
export const PromptParamsSchema = z.record(z.string(), z.any());
export type PromptParams = z.infer<typeof PromptParamsSchema>;

// Define schema for model configuration
export const ModelConfigSchema = z.object({
  provider: z.enum(['openai', 'anthropic', 'local', 'azure']),
  model: z.string(),
  apiKey: z.string().optional(),
  endpoint: z.string().optional(),
  options: z.record(z.string(), z.any()).optional()
});

export type ModelConfig = z.infer<typeof ModelConfigSchema>;

// Default model configurations
const DEFAULT_MODELS: Record<string, ModelConfig> = {
  'default': {
    provider: 'anthropic',
    model: 'claude-3-opus-20240229',
  },
  'fast': {
    provider: 'anthropic',
    model: 'claude-3-haiku-20240307',
  },
  'balanced': {
    provider: 'anthropic',
    model: 'claude-3-sonnet-20240229',
  },
  'openai': {
    provider: 'openai',
    model: 'gpt-4',
  },
  'local': {
    provider: 'local',
    model: 'dynagen-llama-7b',
    endpoint: 'http://localhost:8000/v1/chat/completions'
  }
};

// Store for prompt templates
let promptTemplates: PromptTemplate[] = [];

// Load predefined prompt templates for common tasks
const initializePromptLibrary = (): void => {
  promptTemplates = [
    // Call Analysis Prompt Template
    {
      id: 'call-analysis-basic',
      name: 'Basic Call Analysis',
      description: 'Analyze call transcripts for sentiment, key phrases, and basic metrics',
      systemPrompt: `You are an AI assistant specifically trained to analyze conversations between loan agents and potential customers. 
Your task is to objectively analyze the provided call transcript and extract key information.

Focus on identifying:
- Overall sentiment of the customer (positive, negative, neutral, mixed)
- Key phrases related to loan qualification factors (income, credit, debt, assets, employment)
- Risk indicators (hesitation, inconsistencies, unrealistic expectations)
- How well the agent performed (clarity, empathy, effectiveness, compliance)

Base your analysis solely on observable facts in the transcript. Do not make assumptions.
Format your response according to the specified schema.`,
      userPromptTemplate: `Analyze the following call transcript between a loan agent and a potential customer:

{{transcript}}

Provide a structured analysis that includes:
1. Overall customer sentiment
2. Key phrases that indicate financial situation
3. Any risk indicators with confidence scores
4. A loan qualification score (0-100) if enough information is present
5. Whether a follow-up call is recommended
6. Agent performance metrics (clarity, empathy, effectiveness, compliance)

Format your response as JSON with the following structure:
{
  "sentiment": "positive|negative|neutral|mixed",
  "keyPhrases": ["phrase1", "phrase2", ...],
  "riskIndicators": [
    {
      "type": "string",
      "confidence": number,
      "context": "string"
    },
    ...
  ],
  "loanQualificationScore": number,
  "followUpRecommended": boolean,
  "agentPerformanceMetrics": {
    "clarity": number,
    "empathy": number,
    "effectiveness": number,
    "complianceScore": number
  },
  "summary": "string"
}`,
      parameters: [
        { name: 'transcript', description: 'The call transcript to analyze', required: true }
      ],
      temperature: 0.2,
      maxTokens: 1500,
      responseFormat: 'json',
      version: '1.0',
      lastUpdated: '2025-04-25',
      category: 'call_analysis',
      tags: ['sentiment', 'risk', 'metrics']
    },
    
    // Call Analysis with Compliance Focus
    {
      id: 'call-analysis-compliance',
      name: 'Compliance-Focused Call Analysis',
      description: 'Analyze call transcripts with special focus on regulatory compliance and risk',
      systemPrompt: `You are an AI compliance assistant for DynaGen Lending. Your primary focus is to identify regulatory compliance issues, disclosure requirements, and potential risk factors in loan-related conversations.

You should evaluate the conversation for:
1. Proper disclosures regarding rates, terms, fees
2. Fair lending compliance and non-discrimination
3. TILA (Truth in Lending Act) compliance
4. RESPA (Real Estate Settlement Procedures Act) compliance
5. ECOA (Equal Credit Opportunity Act) compliance
6. UDAAP (Unfair, Deceptive, or Abusive Acts or Practices) concerns

Identify specific statements or omissions that may create compliance risks. Be factual and objective in your assessment.`,
      userPromptTemplate: `Perform a compliance analysis on the following loan call transcript:

{{transcript}}

Provide a detailed assessment focusing on:
1. Regulatory compliance issues detected
2. Required disclosures that were made or missed
3. Potentially problematic language or practices
4. Overall compliance score (0-100)
5. Specific recommendations for improvement

Format your response as structured JSON.`,
      parameters: [
        { name: 'transcript', description: 'The call transcript to analyze', required: true }
      ],
      temperature: 0.1,
      maxTokens: 1500,
      responseFormat: 'json',
      version: '1.0',
      lastUpdated: '2025-04-25',
      category: 'compliance',
      tags: ['regulatory', 'risk', 'disclosures']
    },
    
    // Loan Qualification Assessment
    {
      id: 'loan-qualification-assessment',
      name: 'Loan Qualification Assessment',
      description: 'Evaluate customer information to determine loan qualification potential',
      systemPrompt: `You are an AI loan qualification assistant for DynaGen Lending. Your task is to analyze customer financial information and estimate their qualification potential for various loan products.

Consider the following factors:
- Income stability and amount
- Credit score and history
- Debt-to-income ratio
- Employment history
- Assets and liabilities
- Loan purpose and amount
- Property type and value (for secured loans)

Maintain objectivity in your assessment and adhere to fair lending practices. Do not introduce bias based on non-relevant factors.`,
      userPromptTemplate: `Analyze the following customer information to assess loan qualification potential:

Customer Information:
{{customerInfo}}

Loan Request:
{{loanRequest}}

Provide a structured assessment that includes:
1. Overall qualification score (0-100)
2. Strengths in the application
3. Potential concerns or weaknesses
4. Recommended loan products
5. Suggested next steps

Format your response as JSON with explanations for each assessment point.`,
      parameters: [
        { name: 'customerInfo', description: 'Financial information about the customer', required: true },
        { name: 'loanRequest', description: 'Details about the requested loan', required: true }
      ],
      temperature: 0.3,
      maxTokens: 1200,
      responseFormat: 'json',
      version: '1.0',
      lastUpdated: '2025-04-25',
      category: 'loan_qualification',
      tags: ['assessment', 'qualification', 'recommendation']
    },
    
    // Agent Performance Evaluation
    {
      id: 'agent-performance-evaluation',
      name: 'Agent Performance Evaluation',
      description: 'Evaluate agent performance based on call transcripts and metrics',
      systemPrompt: `You are an AI coach for loan agents at DynaGen Lending. Your task is to analyze agent performance in customer interactions and provide constructive feedback and coaching recommendations.

Evaluate the agent on:
- Communication clarity and effectiveness
- Building rapport and showing empathy
- Product knowledge and solution presentation
- Handling objections and questions
- Compliance with regulations and company policies
- Call structure and time management
- Closing skills and follow-up planning

Be specific, objective, and constructive in your feedback. Include both strengths and areas for improvement, with concrete examples from the interaction.`,
      userPromptTemplate: `Evaluate the performance of this agent based on the following call transcript:

{{transcript}}

Agent Info:
{{agentInfo}}

Provide a structured evaluation that includes:
1. Overall performance score (0-100)
2. Key strengths demonstrated (with specific examples)
3. Areas for improvement (with specific examples)
4. Specific coaching recommendations
5. Compliance assessment

Format your response as structured JSON.`,
      parameters: [
        { name: 'transcript', description: 'The call transcript to analyze', required: true },
        { name: 'agentInfo', description: 'Information about the agent', required: false }
      ],
      temperature: 0.4,
      maxTokens: 1500,
      responseFormat: 'json',
      version: '1.0',
      lastUpdated: '2025-04-25',
      category: 'agent_performance',
      tags: ['evaluation', 'coaching', 'improvement']
    },
    
    // Risk Assessment Prompt
    {
      id: 'risk-assessment-prompt',
      name: 'Loan Risk Assessment',
      description: 'Identify and evaluate risk factors in loan applications',
      systemPrompt: `You are a risk assessment AI for DynaGen Lending. Your task is to identify and evaluate potential risk factors in loan applications and customer interactions.

Focus on identifying the following types of risks:
- Credit risk (ability and willingness to repay)
- Fraud risk (potential misrepresentation or suspicious patterns)
- Operational risk (process or documentation issues)
- Compliance risk (regulatory or policy concerns)
- Market risk (property valuation, market conditions)

For each identified risk, provide a risk level (low, medium, high), justification, and potential mitigation strategies. Be thorough but fair in your assessment, basing conclusions on concrete evidence rather than assumptions.`,
      userPromptTemplate: `Conduct a risk assessment on the following loan application:

Application Data:
{{applicationData}}

Credit Report:
{{creditReport}}

Communication History:
{{communicationHistory}}

Provide a comprehensive risk analysis including:
1. Overall risk rating (low, medium, high)
2. Identified risk factors by category
3. Evidence supporting each risk finding
4. Recommended verification steps or additional information needed
5. Potential risk mitigation strategies

Format your response as structured JSON.`,
      parameters: [
        { name: 'applicationData', description: 'Loan application information', required: true },
        { name: 'creditReport', description: 'Credit report information', required: false },
        { name: 'communicationHistory', description: 'Customer communication history', required: false }
      ],
      temperature: 0.2,
      maxTokens: 1500,
      responseFormat: 'json',
      version: '1.0',
      lastUpdated: '2025-04-25',
      category: 'risk_assessment',
      tags: ['risk', 'fraud', 'compliance']
    }
  ];
};

// Initialize prompt library on module load
initializePromptLibrary();

/**
 * Core function to generate a prompt from a template and parameters
 */
const generatePrompt = (templateId: string, params: PromptParams): { systemPrompt: string, userPrompt: string } => {
  const template = promptTemplates.find(t => t.id === templateId);
  
  if (!template) {
    throw new Error(`Prompt template with ID '${templateId}' not found`);
  }
  
  // Validate required parameters
  template.parameters?.forEach(param => {
    if (param.required && !(param.name in params)) {
      throw new Error(`Required parameter '${param.name}' missing for prompt template '${template.name}'`);
    }
  });
  
  // Replace template variables with actual values
  let userPrompt = template.userPromptTemplate;
  
  for (const [key, value] of Object.entries(params)) {
    const placeholder = `{{${key}}}`;
    // Check if parameter is in the template
    if (userPrompt.includes(placeholder)) {
      // Convert value to string if it's not already
      const stringValue = typeof value === 'string' ? value : JSON.stringify(value, null, 2);
      userPrompt = userPrompt.replace(new RegExp(placeholder, 'g'), stringValue);
    }
  }
  
  return {
    systemPrompt: template.systemPrompt,
    userPrompt
  };
};

/**
 * Call the AI model with the generated prompt
 */
const callModel = async (
  templateId: string, 
  params: PromptParams, 
  modelKey: string = 'default'
): Promise<any> => {
  try {
    // Get model configuration
    const modelConfig = DEFAULT_MODELS[modelKey] || DEFAULT_MODELS.default;
    
    // Get the prompt template
    const template = promptTemplates.find(t => t.id === templateId);
    if (!template) {
      throw new Error(`Prompt template with ID '${templateId}' not found`);
    }
    
    // Generate the prompt
    const { systemPrompt, userPrompt } = generatePrompt(templateId, params);
    
    // Call the appropriate AI provider based on configuration
    let response: string;
    
    switch (modelConfig.provider) {
      case 'anthropic':
        response = await callAnthropicModel({
          systemPrompt,
          userPrompt,
          temperature: template.temperature,
          maxTokens: template.maxTokens,
          model: modelConfig.model
        });
        break;
        
      case 'openai':
        response = await callOpenAIModel({
          systemPrompt,
          userPrompt,
          temperature: template.temperature,
          maxTokens: template.maxTokens,
          model: modelConfig.model
        });
        break;
        
      case 'local':
        response = await callLocalModel({
          systemPrompt,
          userPrompt,
          temperature: template.temperature,
          maxTokens: template.maxTokens,
          model: modelConfig.model,
          endpoint: modelConfig.endpoint
        });
        break;
        
      case 'azure':
        response = await callAzureOpenAIModel({
          systemPrompt,
          userPrompt,
          temperature: template.temperature,
          maxTokens: template.maxTokens,
          model: modelConfig.model,
          endpoint: modelConfig.endpoint,
          apiKey: modelConfig.apiKey
        });
        break;
        
      default:
        throw new Error(`Unknown model provider: ${modelConfig.provider}`);
    }
    
    // Parse response based on expected format
    if (template.responseFormat === 'json') {
      try {
        return JSON.parse(response);
      } catch (error) {
        console.error("Failed to parse JSON response:", error);
        throw new Error("The model returned malformed JSON");
      }
    }
    
    return response;
  } catch (error) {
    console.error("Error calling AI model:", error);
    throw error;
  }
};

/**
 * Implementation for calling Anthropic Claude models
 */
const callAnthropicModel = async ({
  systemPrompt,
  userPrompt,
  temperature,
  maxTokens,
  model
}: {
  systemPrompt: string;
  userPrompt: string;
  temperature?: number;
  maxTokens?: number;
  model: string;
}): Promise<string> => {
  try {
    // This would integrate with your actual API call to Anthropic
    // For now, this is a placeholder implementation
    console.log(`Calling Anthropic model ${model} with system prompt: ${systemPrompt.substring(0, 50)}...`);
    
    const response = await fetch('https://api.anthropic.com/v1/messages', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'x-api-key': import.meta.env.VITE_ANTHROPIC_API_KEY || '',
        'anthropic-version': '2023-06-01'
      },
      body: JSON.stringify({
        model,
        system: systemPrompt,
        messages: [
          {
            role: 'user',
            content: userPrompt
          }
        ],
        temperature: temperature || 0.7,
        max_tokens: maxTokens || 1000
      })
    });
    
    if (!response.ok) {
      throw new Error(`Anthropic API request failed: ${response.statusText}`);
    }
    
    const result = await response.json();
    return result.content[0].text;
  } catch (error) {
    console.error("Failed to call Anthropic API:", error);
    throw error;
  }
};

/**
 * Implementation for calling OpenAI models
 */
const callOpenAIModel = async ({
  systemPrompt,
  userPrompt,
  temperature,
  maxTokens,
  model
}: {
  systemPrompt: string;
  userPrompt: string;
  temperature?: number;
  maxTokens?: number;
  model: string;
}): Promise<string> => {
  try {
    // This would integrate with your actual API call to OpenAI
    // For now, this is a placeholder implementation
    console.log(`Calling OpenAI model ${model} with system prompt: ${systemPrompt.substring(0, 50)}...`);
    
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${import.meta.env.VITE_OPENAI_API_KEY || ''}`
      },
      body: JSON.stringify({
        model,
        messages: [
          {
            role: 'system',
            content: systemPrompt
          },
          {
            role: 'user',
            content: userPrompt
          }
        ],
        temperature: temperature || 0.7,
        max_tokens: maxTokens || 1000
      })
    });
    
    if (!response.ok) {
      throw new Error(`OpenAI API request failed: ${response.statusText}`);
    }
    
    const result = await response.json();
    return result.choices[0].message.content;
  } catch (error) {
    console.error("Failed to call OpenAI API:", error);
    throw error;
  }
};

/**
 * Implementation for calling local models
 */
const callLocalModel = async ({
  systemPrompt,
  userPrompt,
  temperature,
  maxTokens,
  model,
  endpoint
}: {
  systemPrompt: string;
  userPrompt: string;
  temperature?: number;
  maxTokens?: number;
  model: string;
  endpoint?: string;
}): Promise<string> => {
  try {
    // This would integrate with your local model API
    // For now, this is a placeholder implementation
    console.log(`Calling local model ${model} with system prompt: ${systemPrompt.substring(0, 50)}...`);
    
    if (!endpoint) {
      throw new Error("Endpoint URL is required for local model calls");
    }
    
    const response = await fetch(endpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model,
        messages: [
          {
            role: 'system',
            content: systemPrompt
          },
          {
            role: 'user',
            content: userPrompt
          }
        ],
        temperature: temperature || 0.7,
        max_tokens: maxTokens || 1000
      })
    });
    
    if (!response.ok) {
      throw new Error(`Local model API request failed: ${response.statusText}`);
    }
    
    const result = await response.json();
    return result.choices[0].message.content;
  } catch (error) {
    console.error("Failed to call local model API:", error);
    throw error;
  }
};

/**
 * Implementation for calling Azure OpenAI models
 */
const callAzureOpenAIModel = async ({
  systemPrompt,
  userPrompt,
  temperature,
  maxTokens,
  model,
  endpoint,
  apiKey
}: {
  systemPrompt: string;
  userPrompt: string;
  temperature?: number;
  maxTokens?: number;
  model: string;
  endpoint?: string;
  apiKey?: string;
}): Promise<string> => {
  try {
    // This would integrate with Azure OpenAI
    // For now, this is a placeholder implementation
    console.log(`Calling Azure OpenAI model ${model} with system prompt: ${systemPrompt.substring(0, 50)}...`);
    
    if (!endpoint || !apiKey) {
      throw new Error("Endpoint URL and API key are required for Azure OpenAI calls");
    }
    
    const response = await fetch(`${endpoint}/openai/deployments/${model}/chat/completions?api-version=2023-05-15`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'api-key': apiKey
      },
      body: JSON.stringify({
        messages: [
          {
            role: 'system',
            content: systemPrompt
          },
          {
            role: 'user',
            content: userPrompt
          }
        ],
        temperature: temperature || 0.7,
        max_tokens: maxTokens || 1000
      })
    });
    
    if (!response.ok) {
      throw new Error(`Azure OpenAI API request failed: ${response.statusText}`);
    }
    
    const result = await response.json();
    return result.choices[0].message.content;
  } catch (error) {
    console.error("Failed to call Azure OpenAI API:", error);
    throw error;
  }
};

/**
 * Functions for managing prompt templates
 */
const getPromptTemplate = (templateId: string): PromptTemplate | undefined => {
  return promptTemplates.find(t => t.id === templateId);
};

const getAllPromptTemplates = (): PromptTemplate[] => {
  return [...promptTemplates];
};

const getPromptTemplatesByCategory = (category: string): PromptTemplate[] => {
  return promptTemplates.filter(t => t.category === category);
};

const addPromptTemplate = (template: PromptTemplate): void => {
  // Validate the template against the schema
  const validatedTemplate = PromptTemplateSchema.parse(template);
  
  // Check if a template with this ID already exists
  const existingIndex = promptTemplates.findIndex(t => t.id === template.id);
  
  if (existingIndex !== -1) {
    // Update existing template
    promptTemplates[existingIndex] = {
      ...validatedTemplate,
      lastUpdated: new Date().toISOString()
    };
  } else {
    // Add new template
    promptTemplates.push({
      ...validatedTemplate,
      lastUpdated: new Date().toISOString()
    });
  }
};

const removePromptTemplate = (templateId: string): boolean => {
  const initialLength = promptTemplates.length;
  promptTemplates = promptTemplates.filter(t => t.id !== templateId);
  return promptTemplates.length !== initialLength;
};

// Export the service API
const promptEngineeringService = {
  generatePrompt,
  callModel,
  getPromptTemplate,
  getAllPromptTemplates,
  getPromptTemplatesByCategory,
  addPromptTemplate,
  removePromptTemplate
};

export default promptEngineeringService;